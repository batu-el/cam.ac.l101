{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuel/Documents/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Downloading the datasets for 2 language pairs\n",
    "import datasets\n",
    "from datasets import inspect_dataset, load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/rvp2n9dd0c50dlfd6dhp7m9m0000gn/T/ipykernel_36787/878226983.py:1: FutureWarning: inspect_dataset is deprecated and will be removed in the next major version of datasets. Clone the dataset repository from the Hugging Face Hub instead.\n",
      "  inspect_dataset(\"wmt18\", \"data/scripts\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing script for dataset wmt18 can be inspected at /Users/batuel/Documents/l101.experiments.1/data/scripts. The main class is in /Users/batuel/.cache/huggingface/modules/datasets_modules/datasets/wmt18/555a687a5c9cfe8c9393a70305bfb58f26e8326f22dbf99767a28b298b6fa144. You can modify this processing script and use it with `datasets.load_dataset(\"/Users/batuel/Documents/l101.experiments.1/data/scripts\")`.\n"
     ]
    }
   ],
   "source": [
    "inspect_dataset(\"wmt18\", \"data/scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = load_dataset_builder(\n",
    "    \"data/scripts/wmt_utils.py\",\n",
    "    language_pair=(\"tr\", \"en\"),\n",
    "    subsets={\n",
    "        datasets.Split.TRAIN: [\"setimes_2\"],\n",
    "        datasets.Split.VALIDATION: [\"newstest2017\"],\n",
    "        datasets.Split.TEST: [\"newstest2018\"],\n",
    "    },\n",
    ")\n",
    "# Standard version\n",
    "builder.download_and_prepare()\n",
    "ds_tren = builder.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = load_dataset_builder(\n",
    "    \"data/scripts/wmt_utils.py\",\n",
    "    language_pair=(\"de\", \"en\"),\n",
    "    subsets={\n",
    "        datasets.Split.TRAIN: [\n",
    "                \"europarl_v7\",\n",
    "                \"europarl_v8_18\",\n",
    "                \"paracrawl_v1\",\n",
    "                \"commoncrawl\",\n",
    "                \"newscommentary_v13\",\n",
    "                \"czeng_17\",\n",
    "                \"yandexcorpus\",\n",
    "                \"wikiheadlines_fi\",\n",
    "                \"wikiheadlines_ru\",\n",
    "                \"setimes_2\",\n",
    "                \"uncorpus_v1\",\n",
    "                \"rapid_2016\",\n",
    "            ],\n",
    "        datasets.Split.VALIDATION: [\"newstest2017\"],\n",
    "        datasets.Split.TEST: [\"newstest2018\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Standard version\n",
    "builder.download_and_prepare()\n",
    "ds_deen = builder.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tr = dict(ds_tren)['test']['translation']\n",
    "test_de = dict(ds_deen)['test']['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "test_tr_PATH = 'data/datasets/test_tr.jsonl'\n",
    "test_de_PATH = 'data/datasets/test_de.jsonl'\n",
    "\n",
    "with jsonlines.open(test_tr_PATH, mode='w') as writer:\n",
    "    for item in test_tr:\n",
    "        writer.write(item)\n",
    "with jsonlines.open(test_de_PATH, mode='w') as writer:\n",
    "    for item in test_de:\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
