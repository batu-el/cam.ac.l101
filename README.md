# cam.ac.l101

Project Abstract: Minimum Bayes risk (MBR) decoding is a competitive inference method for language generation tasks. It has been observed to improve model performance especially with neural-based utility functions. However, MBR decoding remains impractical for most use cases due to its quadratic computational complexity. This paper aims to develop more efficient hypothesis sampling approaches to address the computational challenges of MBR. Our investigation of the distribution of candidate translations reveals that the candidates are often clustered in distinct regions in the embedding space. Notably, we observe relationships between a candidate's location in embedding space and its MBR score, suggesting that spacial information can be used for more efficient sampling to reduce the number of calls to the utility function. Consequently, we propose two variants of Bayesian optimization for efficient hypothesis sampling in MBR decoding. We believe that further refinements to these methods can further enhance the effectiveness of sampling-based approximations of MBR. We demonstrate our approach with experiments on neural machine translation with two language pairs (DE-EN & TR-EN), using chrF++ and BLEURT as evaluation metrics and MBR utility functions. We make our dataset public to encourage further research into efficient MBR decoding strategies.

Link to the Data: https://drive.google.com/drive/folders/1P7MhmbxsqCjraYLTSMWNX-H0t2A2yFUt?usp=sharing
Link to the Paper: -
